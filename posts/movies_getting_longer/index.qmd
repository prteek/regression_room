---
title: "Are blockbusters getting (reely) longer ?"
author: "Prateek"
date: "2023-07-21"
categories: [hypothesis testing, bootstrap, regression]
image: "movie_coupon.jpg"
toc: true
---

## Introduction

I recently came across an article posing a question:

> Are blockbusters getting (reely) longer?

Fueled by the buzz around Christopher Nolanâ€™s *Oppenheimer* being his longest movie (just over 3 hours), I decided to explore this question using publicly available data.

As an exercise in inference this question can be answered with some analysis.
I fetched top grossing movies in each year from *boxoffice mojo* and movie details from *imdb* and combined them to create the following dataset.

[data](https://raw.githubusercontent.com/prteek/regression_room/refs/heads/main/posts/movies_getting_longer/movies_dataset.csv)


The code to download data is also in this very same .qmd [file](https://github.com/prteek/regression_room/blob/main/posts/movies_getting_longer/index.qmd)
---

## Data

```{python}
#| echo: false
import numpy as np
import pandas as pd
from scipy import stats
import requests
from bs4 import BeautifulSoup as BS
import imdb
import tqdm
from joblib import Parallel, delayed

# Function Definitions
ia = imdb.Cinemagoer()

def get_year_matched_movie_from_title(title: str, year: int):
    """Match titles with their release year in IMDb."""
    movies = ia.search_movie(title)
    for movie in movies:
        if ia.get_movie_main(movie.getID())["data"]["year"] == year:
            return movie
    return None

def get_info_from_movie(movie):
    """Extract runtime and year from an IMDb movie object."""
    run_time = ia.get_movie_main(movie.getID())["data"]["runtimes"][0]
    year = ia.get_movie_main(movie.getID())["data"]["year"]
    return {"release_year": year, "runtime_mins": int(run_time)}

def get_info_for_title(title, year):
    """Package functionality for parallelism."""
    movie = get_year_matched_movie_from_title(title, year)
    if movie is not None:
        title_info = get_info_from_movie(movie)
    else:
        title_info = {"release_year": year}
    title_info["title"] = title
    return title_info

def download_data():
    """Scrape top-grossing movies from Box Office Mojo and fetch details from IMDb."""
    years = range(1990, 2024)
    yearly_top_grossing_url = "https://www.boxofficemojo.com/year/world/{year}/"
    top_n = 10
    all_titles = []

    pbar = tqdm.tqdm(years)
    for year in pbar:
        pbar.set_description(str(year))
        page = requests.get(yearly_top_grossing_url.format(year=year))
        soup = BS(page.content, "html.parser")
        titles = soup.find_all("td", class_="a-text-left mojo-field-type-release_group")

        delayed_year_results = [
            delayed(get_info_for_title)(t.select("a")[0].string, year) for t in titles[:top_n]
        ]
        year_results = Parallel(n_jobs=top_n)(delayed_year_results)
        all_titles.extend(year_results)

    df_movies = pd.DataFrame(all_titles)
    df_movies.to_csv("movies_dataset.csv", index=False)
    return df_movies

# Uncomment below to download data (requires internet access)
# df_movies = download_data()
# df_movies.to_csv('movies_dataset.csv', index=False)

```


```{r}
#| echo: false
suppressPackageStartupMessages(library(tidyverse))
setwd("/Users/prateek/Documents/projects/prteek/regression_room/posts/movies_getting_longer")

```
```{r}
yearly_top_movies = read_delim('movies_dataset.csv',
 show_col_types = FALSE)
head(yearly_top_movies)

```

```{r}
#| echo: false
# Verify data integrity
stopifnot("Error in runtime parsing" = !(any(is.na(yearly_top_movies))))

# Annotate specific movies for visualization
annotations <- data.frame(
  release_year = c(2019, 2019),
  runtime_mins = c(192, 181),
  title = c("Avatar: The Way of Water", "Avengers: Endgame")
)

# Calculate yearly mean runtimes
mean_df <- yearly_top_movies %>%
  group_by(release_year) %>%
  summarise(runtime_mins = mean(runtime_mins))

```

```{r}
# Scatterplot of movie runtime over time
ggplot(yearly_top_movies, aes(x = release_year, y = runtime_mins)) +
  geom_point() + # Scatter points for movie runtimes
  geom_text(data = annotations, aes(label = title), color = "red", nudge_y = 5) + # Annotate specific movies
  geom_line(data = mean_df, aes(y = runtime_mins), color = "brown") + # Line for yearly mean runtimes
  ggtitle("Top Grossing Movies per Year") +
  xlab("Release Year") +
  ylab("Runtime (mins)")

```


## Analysis

### Comparing recent vs old movies

To simplify the analysis we can consider more recent releases (2013-2023) and compare them to releases from much older timeframe (1990-2000). <br/>
The runtime distributions for movies in these 2 categories is different although not significantly (visually).

```{r}
testset <- yearly_top_movies %>%
    mutate(
    label = case_when(
      release_year >= 2013 ~ "recent",
      release_year <= 2000 ~ "old",
      TRUE ~ "other"
    )) %>% filter(label != "other")

ggplot(testset, aes(x=runtime_mins, fill=label)) + geom_density(alpha=0.3)

```

Now we can compare runtimes between two periods. It would have been a straightforward exercise in testing the hypothesis of difference of means using a *t-test* had the distributions of runtimes been more normally distributed. <br/>

Additionally, the cutoff chosen for *old* (<= 2000) and *recent* (>=2013) are arbitrary. We would ideally want a more comprehensive statement about movie runtimes increasing over the years. <br/>

Neverthless, as a preliminary (and simple) analysis we can use bootstrap to compare means of runtimes in the above groups.

```{r}

library(boot)

# Define a function to calculate the difference of means
diff_mean <- function(data, indices) {
  # Resample the data
  resampled_data <- data[indices, ]

  # Calculate means for each group
  mean_group1 <- mean(resampled_data$runtime_mins[resampled_data$label == "old"])
  mean_group2 <- mean(resampled_data$runtime_mins[resampled_data$label == "recent"])

  # Return the difference of means
  return(mean_group2 - mean_group1)
}

set.seed(123)
bootstrap_results <- boot(data = testset, statistic = diff_mean, R = 1000)

# Print bootstrap results
print(bootstrap_results)

# Plot bootstrap distribution
plot(bootstrap_results)

# Calculate confidence interval for the difference of means
ci <- boot.ci(bootstrap_results, type = "perc")
print(ci)

```


If we bootstrap the mean of movie times and take the difference between means of recent release years from old,
there is evidence that blockbuster movies are getting longer in recent years, and the difference can be up to 10 min on average and can be expected to be between 4 min and 16 min. <br/>

So on your next visit to the theatre make sure to get some extra popcorn !!!

### Estimating effect of time
In the want of better precision in identifying the effect of time on movie runtimes, we can formulate a regression problem and estimate the effect of year.

```{r}
#| echo: false
ggplot(yearly_top_movies, aes(x=release_year, y=runtime_mins)) + geom_point() + geom_smooth(method='lm')

```
The plot above partly confirms our intuition about the increasing trend of runtime.

```{r}
lmod <- lm(runtime_mins ~ release_year, yearly_top_movies)
summary(lmod)

```

The regression above supports the hypothesis that *release_year* has positively contributed to movie runtimes at approximately 0.38 min/year. <br/>
Considering our previous finding on average between 1995 and 2018 the runtime increased by approx. 10 min. From the regression estimate the increase is 0.3791 * (2018-1995) = 8.7 min. <br/>

We can certainly run some diagnostics to be sure of our model.

```{r}
#| echo: false
par(mfrow=c(2,2))
plot(lmod)
par(mfrow=c(1,1))

```

The *residuals* appear to have no pattern with fitted values and also have fairly constant variance. There are no significantly high leverage points or outliers. <br/>
However, the errors are not quite normally distributed. <br/>
This can be ignored by relying on large sample size and the fact that other diagnostics are fine. <br/>
But, we shall check if just in case any transformation of *runtime_mins* may help.

```{r}
suppressPackageStartupMessages(library(MASS))
boxcox(lmod, lambda=seq(-1,1,by=0.1))

```
The *Box-Cox* transformation check above hints that there may be some benefit if we used log-transformation (since lambda approximately 0). This thread does not materialise into anything meaningful as upon transformation, the diagnostics do not change materially and the effect size of *release_year* is practically the same (0.32% per year, 0.38 min/year on base of 119 min). So we will not use any transformation in our model.

There may also be some degree of autocorrelation among residuals due to the fact that we're working with timeseries data.
We can test for this autocorrelation and handle it if necessary.

```{r}
#| echo: false
suppressPackageStartupMessages(library(lmtest))

res <- residuals(lmod)
cat(paste("Auto-correlation among residuals: ", round(cor(res[-1], res[-length(res)]), 2)))

dwtest(runtime_mins ~ release_year, data=yearly_top_movies)

```

There doesn't appear to be significant autocorrelation and other model diagnotics appear to be fine.

## Conclusion
There has been a rather steady increase of 0.38 min/year (on average) in movie runtimes as per the dataset we have used.
In effect expect to be seated for about 10 more minutes in your favourite blockbuster compared to when you went to movies as a kid.
